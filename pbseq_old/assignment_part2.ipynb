{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 'markdown cell' below  replace the `???` with the names of those in your group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "???"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment (part 2): classification of cell morphological changes with ResNet\n",
    "_by Phil Harrison (February 2021), verified by David Holmberg (2023)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Helper libraries\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "Don't worry too much about the code in the functions below, but you might want to go through when they are called later on so that you roughly understand what they're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    dirname = 'bbbc021v1_images'\n",
    "    x_orig = np.zeros((660, 256, 256, 3), dtype=np.float32)\n",
    "\n",
    "    for f in range(x_orig.shape[0]):\n",
    "        img    = Image.open(dirname + '/bbbc021v1_%s.png' % str(f))\n",
    "        img    = np.array(img)\n",
    "        x_orig[f] = img\n",
    "\n",
    "    labels = pd.read_csv('bbbc021v1_labels.csv',\n",
    "                          usecols=[\"compound\", \"concentration\", \"moa\"],\n",
    "                          sep=\";\")\n",
    "    y_orig = np.array(labels['moa'])\n",
    "\n",
    "    return x_orig, y_orig\n",
    "\n",
    "def convert_to_one_hot(y, C):\n",
    "    moa_dict = {'Aurora kinase inhibitors': 0, 'Cholesterol-lowering': 1,\n",
    "                'Eg5 inhibitors': 2, 'Protein synthesis': 3, 'DNA replication': 4, 'DNA damage': 5}\n",
    "\n",
    "    y = np.asarray([moa_dict[item] for item in y])\n",
    "    y = np.eye(C)[y]\n",
    "    y = y.astype('float32')\n",
    "\n",
    "    return y\n",
    "\n",
    "def plot_history(model_history, model_name):\n",
    "    fig = plt.figure(figsize=(15, 5), facecolor='w')\n",
    "    ax = fig.add_subplot(131)\n",
    "    ax.plot(model_history.history['loss'])\n",
    "    ax.plot(model_history.history['val_loss'])\n",
    "    ax.set(title=model_name + ': Model loss', ylabel='Loss', xlabel='Epoch')\n",
    "    ax.legend(['train', 'valid'], loc='upper right')\n",
    "    \n",
    "    ax = fig.add_subplot(132)\n",
    "    ax.plot(np.log(model_history.history['loss']))\n",
    "    ax.plot(np.log(model_history.history['val_loss']))\n",
    "    ax.set(title=model_name + ': Log model loss', ylabel='Log loss', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Test'], loc='upper right')    \n",
    "\n",
    "    ax = fig.add_subplot(133)\n",
    "    ax.plot(model_history.history['accuracy'])\n",
    "    ax.plot(model_history.history['val_accuracy'])\n",
    "    ax.set(title=model_name + ': Model accuracy', ylabel='Accuracy', xlabel='Epoch')\n",
    "    ax.legend(['train', 'valid'], loc='upper right')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, model_name,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    title = model_name + ': Confusion Matrix'\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def valid_evaluate(model, model_name):\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_pred = y_pred.argmax(axis=-1)\n",
    "    y_true = Y_valid.argmax(axis=-1)\n",
    "    \n",
    "    class_names = ['Aur', 'Ch', 'Eg5', 'PS', 'DR', 'DS']\n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.figure(figsize=(15,5), facecolor='w')\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, model_name=model_name)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print('')\n",
    "    print('classification report for validation data:')\n",
    "    print(classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_orig, y_orig = load_dataset()\n",
    "Y = convert_to_one_hot(y_orig, 6)\n",
    "X = X_orig/255.\n",
    "\n",
    "n_train = 500\n",
    "\n",
    "random.seed(5026)\n",
    "indices = np.arange(len(Y))\n",
    "random.shuffle(indices)\n",
    "\n",
    "X_train, X_valid = X[indices[:n_train]], X[indices[n_train:]]\n",
    "Y_train, Y_valid = Y[indices[:n_train]], Y[indices[n_train:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet - a deep residual CNN\n",
    "In this section you will implement a deeper state-of-the-art CNN. Specifically, the CNN that you will implement is not too different from the residual CNN presented by He _et al._ (https://arxiv.org/pdf/1512.03385.pdf). \n",
    "\n",
    "A deep residual network contains dozens of residual blocks (see Figure 1) with intermediate normalization. \n",
    "\n",
    "<p>\n",
    "    <img src=\"figs/residual_block.png\" alt=\"drawing\" style=\"width:400px;\"/>\n",
    "    <center>Figure 1. A residual block - the building block of a residual network.</center>\n",
    "</p>\n",
    "\n",
    "The identity mapping is often called a _skip-connection_ or _shortcut_ and has shown to assist in avoiding the degrading effect of training very deep networks --- a degrading effect that is most apparent for \"plain\" networks. Thus, the residual implementation made it possible to successfully train a very deep CNN that outperformed all the other CNNs that came before.\n",
    "\n",
    "<p>\n",
    "    <img src=\"figs/resnet.png\" alt=\"drawing\" style=\"width:1200px;\"/>\n",
    "    <center>Figure 2. Example of a ResNet architecture.</center>\n",
    "</p>\n",
    "\n",
    "### Batch-normalization\n",
    "\n",
    "Normalization of input can help in improving neural networks. The idea of batch-normalization is to take this normalization to the intermediate layers. Specifically, batch-normalization normalizes the layer's output before it goes through the activation function (hence we no longer do activation within the convolutional layer, but have an additional layer for this). This can make the neural network more stable and faster at training.\n",
    "\n",
    "Note: although people sometimes use batch normalization and dropout in the same network, these two approaches can sometimes interfere with one another. Hence we will not use dropout in our ResNet models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful ResNet functions\n",
    "Fill in the `???` in the code below (based on the guidance given after them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(inputs, num_filters, strides):\n",
    "    x = layers.Conv2D(num_filters, kernel_size=(3, 3), strides=strides, padding='same',\n",
    "                      kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(inputs)\n",
    "    return x\n",
    "\n",
    "def ResNet_block(inputs, num_filters, strides):\n",
    "    x = conv(inputs, num_filters=num_filters, strides=strides)\n",
    "    ??? # add batch normalisation\n",
    "    ??? # add a relu activation\n",
    "    x = conv(x, num_filters=num_filters, strides=1)\n",
    "    ??? # add batch normalisation\n",
    "    if strides > 1:\n",
    "        y = conv(inputs, num_filters=num_filters, strides=strides)\n",
    "        ??? # add batch normalisation (for y this time)\n",
    "    else:\n",
    "        y = inputs\n",
    "    z = layers.add([x, y])\n",
    "    z = layers.Activation('relu')(z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ResNet model\n",
    "Coding ResNet is rather more involved than LeNet. Note, Figure 2 is simply for illustrative purposes, the number of filters there, blocks per stack etc., is different to what we would like you to implement. Your task is to fill in the `???` again (based on the guidance given after them) and then jot down the architecture of the model based on the code in this cell and the one above (keep this succinct, i.e. don't try to write what's going on in every layer, or you'll be here all day (!), just jot down the basics in terms of how it is structured). Once you've done that, run the cell and compare your output with ours. \n",
    "\n",
    "Hint: again look to the code given in the lectures for guidance here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "inps = layers.Input((256, 256, 3))\n",
    "x = layers.Conv2D(32, kernel_size=(5, 5), strides=2, padding='same',\n",
    "                 kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(inps)\n",
    "\n",
    "# add batch normalisation\n",
    "# add a relu activation\n",
    "# add max pooling (3x3, with a stride of 2 and 'same' padding)\n",
    "\n",
    "num_stacks = 3\n",
    "num_blocks_per_stack = [3, 4, 3]\n",
    "num_filters_in_stack = [64, 128, 256]\n",
    "\n",
    "for i in range(num_stacks):\n",
    "    num_filters = num_filters_in_stack[i]\n",
    "    for j in range(num_blocks_per_stack[i]):\n",
    "        if(j == 0):\n",
    "            strides = 2\n",
    "        else:\n",
    "            strides = 1\n",
    "        #x = ???  # call the ResNet_block function here with the apprporate inputs\n",
    "        # hint for the call above, look to where we call the conv function within the ResNet block \n",
    "\n",
    "# Add pooling and define output\n",
    "# define a softmax dense output layer (named \"preds\")\n",
    "\n",
    "\n",
    "ResNet = models.Model(inputs=inps, outputs=preds)\n",
    "ResNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did you code in ResNet correctly?\n",
    "At the end of the summary you should see the following:\n",
    "\n",
    "Total params: 4,960,838\n",
    "\n",
    "Trainable params: 4,953,990\n",
    "\n",
    "Non-trainable params: 6,848"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet model description\n",
    "In the 'markdown' cell below replace `???` with your brief summary of your ResNet model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the ResNet model\n",
    "Note for the ResNet model we will use a lower learning rate of 0.0001 as opposed to the default value of 0.001 that we used for the LeNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "#ResNet.compile(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and evaluate the ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 50\n",
    "\n",
    "history = ResNet.fit(X_train, Y_train,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=n_epochs,\n",
    "                     validation_data=(X_valid, Y_valid),\n",
    "                     verbose=2)\n",
    "\n",
    "plot_history(history, 'ResNet')\n",
    "valid_evaluate(ResNet, 'ResNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple runs of the same model\n",
    "Again, as we did for the LeNet model, re-run your ResNet model 5 times to compute the mean 'weighted avg f1-score'. Show this in the code cell below. For my five runs I got:\n",
    "\n",
    "(0.769 + 0.815 + 0.720 + 0.777 + 0.842) / 5 = 0.785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "Your probably noticed that the training was quite eratic for your ResNet model above (i.e. the training curve was quite jaggedy). We could combat this with changes to the model architecture, the batch size and learning rate. We could also perhaps improve things with data augmentation. We will not explore these modifications here though.\n",
    "\n",
    "This was a big model that we trained, with almost 5 million parameters. With only 500 images for training this was rather ambitious! A better way to deal with a small dataset size, when we still want to fit a fairly complex and descriptive model (that will hopefully make good predictions), is to use transfer learning. This will be the focus of part 4 of the assignemnt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
