{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks (CNNs) for the diagnosis of oral cancer\n",
    "\n",
    "_by Phil Harrison (February 2021)_\n",
    "\n",
    "### Overview\n",
    "In this lab you'll learn how to implement your own convolutional neural networks (CNNs) for classifying human oral cells as either 'healthy' or 'tumor'.\n",
    "\n",
    "### Dataset\n",
    "We will be using a simplified subset of the data analysed in the paper \"Deep Convolutional Neural Networks For Detecting Cellular Changes Due To\n",
    "Malignancy\" by Wieslander et al. (2017) (http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w1/Wieslander_Deep_Convolutional_Neural_ICCV_2017_paper.pdf). The CNNs we'll be training in this lab will be more basic than those used in that paper.\n",
    "\n",
    "A quote from Weislander et al. regarding the dataset: \n",
    "\n",
    "\"_The cell samples were collected at SÃ¶dersjukhuset in Stockholm. The patients have mixed genders, are non smoking, some are human papillomavirus (HPV) positive and some are not, and they have an age span of 47-77 years. From each patient samples were collected with a brush that is scraped at areas of interest in the oral cavity. Each scrape is then smeared out on a glass, which is then stained to highlight important cellular structures_\".\n",
    "\n",
    "<p>\n",
    "    <img src=\"figs/oral_cancer_summary.png\" alt=\"drawing\"  style=\"width:800px;\"/>\n",
    "    <center>Figure 1. Oral cancer data summary.</center>\n",
    "</p>\n",
    "\n",
    "Example cell images Weislander et al. used are shown below. These images were greyscale and 80 x 80 pixels.\n",
    "\n",
    "<p>\n",
    "    <img src=\"figs/cancer_cells.png\" alt=\"drawing\" style=\"width:800px;\"/>\n",
    "    <center>Figure 2. Example oral cancer cell images.</center>\n",
    "</p>\n",
    "\n",
    "To simplify the data for the lab I took smaller crops of 48 x 48 pixels around each cell and only took a subsample of the entire dataset. All the images were then shuffled and allocated to the training, validation or test set. Hence, here we are solving a simpler classification task than the more robust one carried out by Weislander et al. where the data were not shuffled and cells from a given patient could only be in one of the three sets. A more robust and generalizable approach would be to do what Weislander et al. did, so keep this in mind.\n",
    "\n",
    "### Note\n",
    "Some of the code cells below are kind of boiler plate code, for getting things in the right format, plotting various things and what not. This might be of interest for some of you that want to take these things further and use them on other datasets, for others they will just be distracting. Don't get too distracted. The main parts are those code cells where I ask you to modify things. Either way, you need to run these code cells for the other parts to run properly...\n",
    "\n",
    "Also below we use `generators` to load the data from directories in small batches. This is useful if your dataset is bigger than fits into the GPU memory. GPUs are super fast for fitting neural networks, much faster than CPUs, although they have less memory space than CPUs. Don't worry too much about these generators. I put them here that you can refer back to this code, should any of you decide to take deep learning further, such as if you decide to do your thesis project in this area. This is the only place we will work with them. The data for the assignment tomorrow is small enough that it fits onto memory and we won't be needing them there..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages\n",
    "Somewhat more packages than we loaded before. Nothing to worry about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Helper libraries\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "\n",
    "from tifffile import imread\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting and summarising functions\n",
    "Don't worry too much about the code in the functions below, but you might want to go through when they are called later on so that you roughly understand what they're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_history, model_name):\n",
    "    fig = plt.figure(figsize=(20,6), facecolor='w')\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.plot(model_history.history['loss'])\n",
    "    ax.plot(model_history.history['val_loss'])\n",
    "    ax.set(title=model_name + ': Model loss', ylabel='Loss', xlabel='Epoch')\n",
    "    ax.legend(['Training', 'Validation'], loc='upper left')\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.plot(model_history.history['accuracy'])\n",
    "    ax.plot(model_history.history['val_accuracy'])\n",
    "    ax.set(title=model_name + ': Model Accuracy', \n",
    "           ylabel='Accuracy', xlabel='Epoch')\n",
    "    ax.legend(['Training', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, model_name,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    title = model_name\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def plot_sample_images():\n",
    "    # plot 5 healthy cells form training data\n",
    "    print('random sample of healthy cells from training set')\n",
    "    print('')\n",
    "    all_cells = glob.glob(train_healthy_dir + '/' '*')\n",
    "    n_cells = len(all_cells)\n",
    "    to_plot = np.random.choice(n_cells, 5, replace=False)\n",
    "\n",
    "    plt.figure(figsize=(20, 120), facecolor='w')\n",
    "\n",
    "    for i in range(5):\n",
    "        im = imread(all_cells[to_plot[i]])\n",
    "        sub_index = 151 + i\n",
    "        plt.subplot(sub_index)\n",
    "        plt.imshow(im[:, :, 0], cmap='gray')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # plot 5 tumor cells form training data\n",
    "    print('')\n",
    "    print('random sample of tumor cells from training set')\n",
    "    print('')\n",
    "    all_cells = glob.glob(train_tumor_dir + '/' '*')\n",
    "    n_cells = len(all_cells)\n",
    "    to_plot = np.random.choice(n_cells, 5, replace=False)\n",
    "\n",
    "    plt.figure(figsize=(20, 120), facecolor='w')\n",
    "\n",
    "    for i in range(5):\n",
    "        im = imread(all_cells[to_plot[i]])\n",
    "        sub_index = 151 + i\n",
    "        plt.subplot(sub_index)\n",
    "        plt.imshow(im[:, :, 0], cmap='gray')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def data_summary():\n",
    "    print('no. training healthy images:', len(os.listdir(train_healthy_dir)))\n",
    "    print('no. training tumor images:', len(os.listdir(train_tumor_dir)))\n",
    "    print('')\n",
    "    print('no. validation healthy images:', len(os.listdir(validation_healthy_dir)))\n",
    "    print('no. validation tumor images:', len(os.listdir(validation_tumor_dir)))\n",
    "    print('')\n",
    "    print('no. test healthy images:', len(os.listdir(test_healthy_dir)))\n",
    "    print('no. test tumor images:', len(os.listdir(test_tumor_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify data directories\n",
    "Run the cell below to define the directories where our image data has been placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory we will store our dataset\n",
    "base_dir = 'HPV/data_v3'\n",
    "\n",
    "# directories for our training, validation and test splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# directory with our training healthy cell images\n",
    "train_healthy_dir = os.path.join(train_dir, 'healthy')\n",
    "\n",
    "# directory with our training tumor cell images\n",
    "train_tumor_dir = os.path.join(train_dir, 'tumor')\n",
    "\n",
    "# directory with our validation healthy cell images\n",
    "validation_healthy_dir = os.path.join(validation_dir, 'healthy')\n",
    "\n",
    "# directory with our validation tumor cell images\n",
    "validation_tumor_dir = os.path.join(validation_dir, 'tumor')\n",
    "\n",
    "# directory with our test healthy cell images\n",
    "test_healthy_dir = os.path.join(test_dir, 'healthy')\n",
    "\n",
    "# directory with our test tumor cell images\n",
    "test_tumor_dir = os.path.join(test_dir, 'tumor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data summary\n",
    "Run the code cell below to get a summary of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample images\n",
    "Run the jupyter cell below to see a sample of the 48 x 48 greyscale images\n",
    "(you can run this multiple times to get different samples and to think about what the differences between the healthy and cancer cells might be)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic convolutional neural network (CNN)\n",
    "\n",
    "Convolutional Neural Networks (CNNs) use convolutions instead of the normal fully connected layers, which have proven to be highly successful for image recognition tasks. By convolving filters on the input layer and outputting the results to the next layer, the CNN \"detects\" (or learns) features at different levels of abstraction throughout the network. With lower-level abstractions (like edges and blobs) in the early layers, and higher-level abstractions (like cells) in deeper layers. The figure below shows the LeNet inspired CNN that we will shortly be implementing.\n",
    "\n",
    "<p>\n",
    "    <img src=\"figs/CNN.png\" alt=\"drawing\" style=\"width:1200px;\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some additional bits and pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len = 48\n",
    "y_len = 48\n",
    "batch_size = 32\n",
    "n_epochs = 50\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print('TRAINING DATA:')\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(x_len, y_len),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary')\n",
    "\n",
    "print('')\n",
    "print('VALIDATION DATA:')\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(x_len, y_len),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "print('')\n",
    "print('TEST DATA:')\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(x_len, y_len),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "train_steps = (len(os.listdir(train_healthy_dir)) + len(os.listdir(train_tumor_dir))) // batch_size\n",
    "validation_steps = (len(os.listdir(validation_healthy_dir)) + len(os.listdir(validation_tumor_dir))) // batch_size\n",
    "test_steps = (len(os.listdir(test_healthy_dir)) + len(os.listdir(test_tumor_dir))) // batch_size\n",
    "    \n",
    "def valid_evaluate(model):\n",
    "    y_pred = model.predict_generator(validation_generator, validation_steps+1)\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_true = validation_generator.classes\n",
    "    class_names = ['healthy', 'tumor']\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.figure(figsize=(15,5), facecolor='w')\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, model_name='confusion matrix for validation data')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print('')\n",
    "    print('classification report for validation data:')\n",
    "    print(classification_report(y_true, y_pred, digits=3))\n",
    "\n",
    "def test_evaluate(model):\n",
    "    y_pred = model.predict_generator(test_generator, test_steps+1)\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_true = test_generator.classes\n",
    "    class_names = ['healthy', 'tumor']\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.figure(figsize=(15,5), facecolor='w')\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, model_name='confusion matrix for test data')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print('')\n",
    "    print('classification report for test data:')\n",
    "    print(classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First pass CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and summarise the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = layers.Input((x_len, y_len, 1)) # input image dimensions\n",
    "\n",
    "# convolution and pooling layers\n",
    "x = layers.Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu')(inps)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# fully connected layers\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "preds = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "CNN1 = models.Model(inputs=inps, outputs=preds)\n",
    "CNN1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN1.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizers.Adam(lr=0.001),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and evaluate the model\n",
    "Note: When you run the cell below you will probably get a WARNING message about sample_weight modes. This is a small bug in the version of TesorFlow we are using and has been fixed in more recent versions. You can safely ignore this warning message, it doesn't affect anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = CNN1.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    verbose=2)\n",
    "\n",
    "plot_history(history, 'CNN1')\n",
    "\n",
    "valid_evaluate(CNN1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative model architectures\n",
    "In the code cells below try some alternative model architectures. Use the 'weighted avg f1-score' on the validation data to compare different model architectures and to decide which one was best.\n",
    "\n",
    "* try fitting two different models with different numbers of convolutional layers (you can have between two and five for this data, more than five convolutional layers does not work for this data due to the shrinking of the spatial dimensions of the filter maps as they go through max pooling)\n",
    "* you can also play around with the number of filters for each convolutional layer\n",
    "* and you can experiment with different values for the dropout rate, or with no dropout at all (by either setting the dropout rate to 0.0 or removing the dropout code line all together)\n",
    "* finally, you are free to explore different numbers of neurons for the final dense layer (just before our prediction (preds) layer).\n",
    "\n",
    "#### Notes: \n",
    "* if your model does not seem to have converged after 25 epochs (the default value) you can also raise the number of epochs to train for.\n",
    "* name your model CNN2, CNN3 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and summarise your CNN2 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile CNN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate CNN2 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and summarise your CNN3 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile CNN3 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate CNN3 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding data augmentation\n",
    "\n",
    "DATA AUGMENTATION: \"_An approach to overcome the challenges posed by a limited amount of annotated training data. Augmentation is performed by artificially generating more annotated training data, typically by mirroring and rotating the original images_\".\n",
    "\n",
    "We will use the same 8x data augmentation as used by Wieslander et al.:\n",
    "\n",
    "<p>\n",
    "    <img src=\"figs/augmentation.png\" alt=\"drawing\" style=\"width:1000px;\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add the data augmentations above via training data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=90,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(x_len, y_len),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = layers.Input((x_len, y_len, 1)) # input image dimensions\n",
    "\n",
    "# convolution and pooling layers\n",
    "x = layers.Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu')(inps)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# fully connected layers\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "preds = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "CNN1_aug = models.Model(inputs=inps, outputs=preds)\n",
    "CNN1_aug.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN1_aug.compile(loss='binary_crossentropy',\n",
    "                 optimizer=optimizers.Adam(lr=0.001),\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "history = CNN1_aug.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    verbose=2)\n",
    "\n",
    "plot_history(history, 'CNN1_aug')\n",
    "\n",
    "valid_evaluate(CNN1_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did data augmentation help?\n",
    "When I ran these model I got a `weighted avg f1 score` of 0.803 without augmentation (CNN1) and 0.810 with augmentation (CNN1_aug). So perhaps some help here in this case. Note this could have been due to stochasticity in the local minima the two models found (see the `Final note` section at the end of this notebook). Hence for your runs, you may have gotten different results. There are also other (fancier) augmentations that one can try, that can sometimes help, such as shifts, sheers, zooms etc.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "Besides using dropout we can also explore L1 and/or L2 regularization. Run the code cells below to re-run our first pass model with L2 regularization of the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(x_len, y_len),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = layers.Input((x_len, y_len, 1)) # input image dimensions\n",
    "\n",
    "# convolution and pooling layers\n",
    "x = layers.Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.0001))(inps)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.0001))(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# fully connected layers\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "preds = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "CNN1_L2 = models.Model(inputs=inps, outputs=preds)\n",
    "CNN1_L2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN1_L2.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizers.Adam(lr=0.001),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = CNN1_L2.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    verbose=2)\n",
    "\n",
    "plot_history(history, 'CNN1_L2')\n",
    "\n",
    "valid_evaluate(CNN1_L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did L2 regularisation help?\n",
    "When I ran these model I got a `weighted avg f1 score` of 0.803 without regularization (CNN1) and 0.794 with regularization (CNN1_aug). So not much help in this case. Again, however, see the `Final note` section at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation on test data\n",
    "As we used the validation data to determine the best CNN architecture, we need to perform a final evaluation on test data (i.e. held-out data that the model has not yet seen). In the parenthesis below place replace `???` with the name of your model that performed best on the validation data. On this test data I got a weighted average f1-score of 0.841 with my best model. Did you manage to beat me? :)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluate(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final notes\n",
    "Due to stochasticity in how the models are defined, you may have not hit on the best model. You can run the same neural network model and get different results. We will acommodate for this issue during the assignment tomorrow. Ideally, when one has time, one would run the same model several times and take the average results. \n",
    "\n",
    "Combing the approaches we used (i.e. using regularization of the weights and data augmentation) on your best model from above (if it wasn't CNN1) might give a better model still. We also have some inbalance in the class weights, accomodating for this when you fit the models can also help.\n",
    "\n",
    "Also, as yesterday, with a different train/validation/test split we can get different results - we can combat this with cross-validation.\n",
    "\n",
    "Training neural networks is an exploratory process. In some cases - for some datasets - adding certain things (such as additional layers, data augmentation, weight regularization etc.) can help a lot. In other cases the improvements may be marginal or may even degrade the results. There aren't a lot of hard and fast rules in this field (currently) so exploaration is the name of the game. Having a large arsenal of things to try is nevertheless very useful!\n",
    "\n",
    "Finally, we simplified the problem above by mixing up the cells, such that cells from the same individual could be in all the splits of the data. As said above, it would have been more rigerous for us to have it such that all the cells from an individual could only appear in one of the splits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
